{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detection System\n",
    "\n",
    "This is the code for training a face mask detection system using Pytorch. The model is trained on a dataset of images containing people with and without face masks. The goal is to classify whether a person is wearing a mask or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # For file and directory operations\n",
    "import time # For time operations\n",
    "import cv2 # For image processing\n",
    "import gc # Force garbage collection\n",
    "import kagglehub # For Kaggle API (Dataset download)\n",
    "import xml.etree.ElementTree as et # For parsing XML files\n",
    "from tqdm import tqdm # For progress bar\n",
    "from sklearn.model_selection import train_test_split # For splitting the dataset\n",
    "import albumentations as A  # Library for advanced augmentations\n",
    "import numpy as  np # For numerical operations\n",
    "import pandas as pd # For data manipulation\n",
    "import torch # For Machine Learning\n",
    "import torch.nn as nn # For neural networks\n",
    "import torch.optim as optim # For optimization\n",
    "from torch.utils.data import Dataset, DataLoader # For data loading\n",
    "from torchvision import transforms # For data transformations\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights # For pre-trained models\n",
    "from sklearn.metrics import classification_report # For evaluation metrics\n",
    "import matplotlib.pyplot as plt # For plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the libraries are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS Name: nt\n",
      "OpenCV Version: 4.11.0\n",
      "KaggleHub Version: 0.3.12\n",
      "Albumentations Version: 2.0.6\n",
      "NumPy Version: 2.2.5\n",
      "Pandas Version: 2.2.3\n",
      "Torch Version: 2.7.0+cu126\n"
     ]
    }
   ],
   "source": [
    "print(\"OS Name:\", os.name)\n",
    "print(\"OpenCV Version:\", cv2.__version__)\n",
    "print(\"KaggleHub Version:\", kagglehub.__version__)\n",
    "print(\"Albumentations Version:\", A.__version__)\n",
    "print(\"NumPy Version:\", np.__version__)\n",
    "print(\"Pandas Version:\", pd.__version__)\n",
    "print(\"Torch Version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path of the Dataset C:\\Users\\basee\\.cache\\kagglehub\\datasets\\andrewmvd\\face-mask-detection\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(\"andrewmvd/face-mask-detection\")\n",
    "print(\"Path of the Dataset\", dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse XML Annotations to CSV from the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing XML files: 100%|██████████| 853/853 [00:10<00:00, 80.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations saved to annotations.csv.\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "          image_name         label  xmin  ymin  xmax  ymax  x_center  \\\n",
      "0  maksssksksss0.png  without_mask    79   105   109   142  0.183594   \n",
      "1  maksssksksss0.png     with_mask   185   100   226   144  0.401367   \n",
      "2  maksssksksss0.png  without_mask   325    90   360   141  0.668945   \n",
      "3  maksssksksss1.png     with_mask   321    34   354    69  0.843750   \n",
      "4  maksssksksss1.png     with_mask   224    38   261    73  0.606250   \n",
      "\n",
      "   y_center  width_norm  height_norm  img_width  img_height  \n",
      "0  0.337432    0.058594     0.101093        512         366  \n",
      "1  0.333333    0.080078     0.120219        512         366  \n",
      "2  0.315574    0.068359     0.139344        512         366  \n",
      "3  0.330128    0.082500     0.224359        400         156  \n",
      "4  0.355769    0.092500     0.224359        400         156  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_xml_to_csv(xml_folder, output_csv=\"annotations.csv\"):\n",
    "    data = []\n",
    "    \n",
    "    # Loop through all XML files in the specified folder\n",
    "    for xml_file in tqdm(os.listdir(xml_folder), desc=\"Parsing XML files\"): # Using tqdm for progress bar\n",
    "        if not xml_file.endswith('.xml'): # Skip non-XML files\n",
    "            continue\n",
    "        \n",
    "        xml_path = os.path.join(xml_folder, xml_file) # Construct full path\n",
    "        tree = et.parse(xml_path) # Parse the XML file\n",
    "        root = tree.getroot() # Get the root element\n",
    "        \n",
    "        size = root.find('size') # Find the size element\n",
    "        width = int(size.find('width').text) # Extract width\n",
    "        height = int(size.find('height').text) # Extract height\n",
    "        \n",
    "        # Extract each object (face) in the image\n",
    "        for obj in root.findall('object'):\n",
    "            label = obj.find('name').text # Extract label\n",
    "            bbox = obj.find('bndbox') # Extract bounding box\n",
    "            xmin = int(bbox.find('xmin').text) \n",
    "            ymin = int(bbox.find('ymin').text)\n",
    "            xmax = int(bbox.find('xmax').text)\n",
    "            ymax = int(bbox.find('ymax').text)\n",
    "            \n",
    "            x_center = (xmin + xmax) / (2 * width)\n",
    "            y_center = (ymin + ymax) / (2 * height)\n",
    "\n",
    "            bbox_width = (xmax - xmin) / width\n",
    "            bbox_height = (ymax - ymin) / height\n",
    "            \n",
    "            # Append data to the list\n",
    "            data.append([\n",
    "                xml_file.replace('.xml', '.png'), # Replace XML extension with PNG (Image names and XML names are the same)\n",
    "                label,\n",
    "                xmin, ymin, xmax, ymax,\n",
    "                x_center, y_center, bbox_width, bbox_height,\n",
    "                width, height\n",
    "            ])\n",
    "    \n",
    "    # Create a DataFrame from the list\n",
    "    columns = [\n",
    "        'image_name', 'label', \n",
    "        'xmin', 'ymin', 'xmax', 'ymax', \n",
    "        'x_center', 'y_center', 'width_norm', 'height_norm',\n",
    "        'img_width', 'img_height'\n",
    "    ]\n",
    "    dataframe = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    dataframe.to_csv(output_csv, index=False) # Save DataFrame to CSV\n",
    "\n",
    "    print(f\"Annotations saved to {output_csv}.\")\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "# Main script\n",
    "# Dataset path\n",
    "xml_folder = r\"C:\\Users\\basee\\.cache\\kagglehub\\datasets\\andrewmvd\\face-mask-detection\\versions\\1\\annotations\"\n",
    "dataframe = parse_xml_to_csv(xml_folder)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2442/2442 [00:23<00:00, 104.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [00:07<00:00, 115.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [00:07<00:00, 115.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Training data...\n",
      "Training data saved.\n",
      "\n",
      "Saving Validation data...\n",
      "Validation data saved.\n",
      "\n",
      "Saving Test data...\n",
      "Test data saved.\n",
      "\n",
      "Memory cleaned up.\n",
      "\n",
      "Preprocessing complete! Data saved to processed_data/.\n"
     ]
    }
   ],
   "source": [
    "INPUT_CSV = \"annotations.csv\"  # Path to the CSV file with annotations\n",
    "IMAGE_DIR = r\"C:\\Users\\basee\\.cache\\kagglehub\\datasets\\andrewmvd\\face-mask-detection\\versions\\1\\images\" # Directory containing images\n",
    "\n",
    "OUTPUT_DIR = \"processed_data/\" # Directory to save processed data\n",
    "TARGET_SIZE = (224, 224) # Target size for resizing images\n",
    "\n",
    "# Augmentation pipeline for training data\n",
    "augmenter = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=20, p=0.3),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels'])) # Using Pascal VOC format for bounding boxes\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(image_path, target_size):\n",
    "    img = cv2.imread(image_path) # Read image using OpenCV\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "    img = cv2.resize(img, target_size) # Resize to target size\n",
    "    return img\n",
    "\n",
    "# Function to normalize bounding box coordinates\n",
    "def normalize_bbox(bbox, orig_size, target_size):\n",
    "    xmin, ymin, xmax, ymax = bbox # Unpack bounding box coordinates\n",
    "    orig_w, orig_h = orig_size # Original image size\n",
    "    \n",
    "    # Scale factors\n",
    "    w_scale = target_size[0] / orig_w\n",
    "    h_scale = target_size[1] / orig_h\n",
    "    \n",
    "    # Normalize bounding box coordinates\n",
    "    new_xmin = int(xmin * w_scale)\n",
    "    new_ymin = int(ymin * h_scale)\n",
    "    new_xmax = int(xmax * w_scale)\n",
    "    new_ymax = int(ymax * h_scale)\n",
    "    \n",
    "    return [new_xmin, new_ymin, new_xmax, new_ymax]\n",
    "\n",
    "# Function to process the dataset\n",
    "def process_dataset(df, augment=False):\n",
    "    processed_data = []\n",
    "    \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_path = os.path.join(IMAGE_DIR, row['image_name']) # Construct full image path\n",
    "        original_size = (row['img_width'], row['img_height']) # Original image size\n",
    "        bbox = [row['xmin'], row['ymin'], row['xmax'], row['ymax']] # Bounding box coordinates\n",
    "        \n",
    "        img = load_and_preprocess_image(img_path, TARGET_SIZE) # Load and preprocess image\n",
    "        \n",
    "        new_bbox = normalize_bbox(bbox, original_size, TARGET_SIZE) # Normalize bounding box coordinates\n",
    "        \n",
    "        # If augmenting, apply augmentations\n",
    "        if augment:\n",
    "            augmented = augmenter(\n",
    "                image=img,\n",
    "                bboxes=[new_bbox],\n",
    "                class_labels=[row['label']]\n",
    "            )\n",
    "            img = augmented['image']\n",
    "            new_bbox = augmented['bboxes'][0] if augmented['bboxes'] else new_bbox \n",
    "        \n",
    "        img = img / 255.0 # Normalize image \n",
    "        \n",
    "        # Append processed data\n",
    "        processed_data.append({\n",
    "            'image': img,\n",
    "            'bbox': new_bbox,\n",
    "            'label': 1 if row['label'] == 'with_mask' else 0,  # Binary encoding\n",
    "            'original_image': row['image_name']\n",
    "        })\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Main script\n",
    "# Check if the output directory exists, if not create it\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "# Load the CSV file\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    " \n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42) # Split into train and test sets\n",
    "train_df, validation_df = train_test_split(train_df, test_size=0.25, random_state=42) # Split train set into train and validation sets\n",
    "\n",
    "# Process training dataset     \n",
    "print(\"Processing Training set...\")\n",
    "train_data = process_dataset(train_df, augment=True)\n",
    "\n",
    "# Process validation dataset \n",
    "print(\"\\nProcessing Validation set...\")\n",
    "validation_data = process_dataset(validation_df)\n",
    "\n",
    "# Process test dataset\n",
    "print(\"\\nProcessing Test set...\")\n",
    "test_data = process_dataset(test_df)\n",
    "    \n",
    "# Save processed training data to .npz files\n",
    "print(\"\\nSaving Training data...\")\n",
    "np.savez_compressed(\n",
    "    os.path.join(OUTPUT_DIR, \"train.npz\"),\n",
    "    images=np.array([x['image'] for x in train_data]),\n",
    "    bboxes=np.array([x['bbox'] for x in train_data]),\n",
    "    labels=np.array([x['label'] for x in train_data])\n",
    ")\n",
    "print(\"Training data saved.\")\n",
    "\n",
    "# Save processed validation data to .npz files\n",
    "print(\"\\nSaving Validation data...\")\n",
    "np.savez_compressed(\n",
    "    os.path.join(OUTPUT_DIR, \"validation.npz\"),\n",
    "    images=np.array([x['image'] for x in validation_data]),\n",
    "    bboxes=np.array([x['bbox'] for x in validation_data]),\n",
    "    labels=np.array([x['label'] for x in validation_data])\n",
    ")\n",
    "print(\"Validation data saved.\")\n",
    "\n",
    "# Save processed test data to .npz files\n",
    "print(\"\\nSaving Test data...\")\n",
    "np.savez_compressed(\n",
    "    os.path.join(OUTPUT_DIR, \"test.npz\"),\n",
    "    images=np.array([x['image'] for x in test_data]),\n",
    "    bboxes=np.array([x['bbox'] for x in test_data]),\n",
    "    labels=np.array([x['label'] for x in test_data])\n",
    ")\n",
    "print(\"Test data saved.\")\n",
    "\n",
    "del train_data, validation_df, test_data # Delete variables to free up memory\n",
    "gc.collect() # Force garbage collection for memory cleanup\n",
    "print(\"\\nMemory cleaned up.\")\n",
    "    \n",
    "print(f\"\\nPreprocessing complete! Data saved to {OUTPUT_DIR}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Processed Data...\n",
      "Data Loaded.\n",
      "\n",
      "Creating DataLoaders...\n",
      "DataLoaders Created.\n",
      "\n",
      "Initializing Model...\n",
      "Model Initialized.\n",
      "\n",
      "Defining Loss Function and Optimizer...\n",
      "Loss Function and Optimizer Defined.\n",
      "\n",
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "\n",
      "Training on 2442 samples\n",
      "Validating on 815 samples\n",
      "\n",
      "\n",
      "Starting Training...\n",
      "Epoch 1/20\n",
      "Train Loss: 0.5178 | Validation Loss: 0.6096 | Validation Acc: 0.6834\n",
      "Model saved!\n",
      "\n",
      "\n",
      "Epoch 2/20\n",
      "Train Loss: 0.4670 | Validation Loss: 0.5122 | Validation Acc: 0.7755\n",
      "Model saved!\n",
      "\n",
      "\n",
      "Epoch 3/20\n",
      "Train Loss: 0.4627 | Validation Loss: 0.4769 | Validation Acc: 0.7939\n",
      "Model saved!\n",
      "\n",
      "\n",
      "Epoch 4/20\n",
      "Train Loss: 0.4479 | Validation Loss: 0.4748 | Validation Acc: 0.7939\n",
      "Model saved!\n",
      "\n",
      "\n",
      "Epoch 5/20\n",
      "Train Loss: 0.4343 | Validation Loss: 0.4676 | Validation Acc: 0.8000\n",
      "Model saved!\n",
      "\n",
      "\n",
      "Epoch 6/20\n",
      "Train Loss: 0.4183 | Validation Loss: 0.4702 | Validation Acc: 0.8061\n",
      "\n",
      "\n",
      "Epoch 7/20\n",
      "Train Loss: 0.4131 | Validation Loss: 0.4797 | Validation Acc: 0.8061\n",
      "\n",
      "\n",
      "Epoch 8/20\n",
      "Train Loss: 0.3847 | Validation Loss: 0.5154 | Validation Acc: 0.7804\n",
      "\n",
      "\n",
      "Epoch 9/20\n",
      "Train Loss: 0.3363 | Validation Loss: 0.4593 | Validation Acc: 0.8110\n",
      "Model saved!\n",
      "\n",
      "\n",
      "Epoch 10/20\n",
      "Train Loss: 0.3029 | Validation Loss: 0.4684 | Validation Acc: 0.8110\n",
      "\n",
      "\n",
      "Epoch 11/20\n",
      "Train Loss: 0.2893 | Validation Loss: 0.4740 | Validation Acc: 0.8098\n",
      "\n",
      "\n",
      "Epoch 12/20\n",
      "Train Loss: 0.2760 | Validation Loss: 0.5020 | Validation Acc: 0.8147\n",
      "\n",
      "\n",
      "Epoch 13/20\n",
      "Train Loss: 0.2533 | Validation Loss: 0.4849 | Validation Acc: 0.8123\n",
      "\n",
      "\n",
      "Epoch 14/20\n",
      "Train Loss: 0.2596 | Validation Loss: 0.5006 | Validation Acc: 0.8123\n",
      "\n",
      "\n",
      "Epoch 15/20\n",
      "Train Loss: 0.2461 | Validation Loss: 0.4940 | Validation Acc: 0.8086\n",
      "\n",
      "\n",
      "Epoch 16/20\n",
      "Train Loss: 0.2422 | Validation Loss: 0.4968 | Validation Acc: 0.8061\n",
      "\n",
      "\n",
      "Epoch 17/20\n",
      "Train Loss: 0.2492 | Validation Loss: 0.5002 | Validation Acc: 0.8123\n",
      "\n",
      "\n",
      "Epoch 18/20\n",
      "Train Loss: 0.2468 | Validation Loss: 0.5006 | Validation Acc: 0.8110\n",
      "\n",
      "\n",
      "Epoch 19/20\n",
      "Train Loss: 0.2415 | Validation Loss: 0.4925 | Validation Acc: 0.8135\n",
      "\n",
      "\n",
      "Epoch 20/20\n",
      "Train Loss: 0.2500 | Validation Loss: 0.4970 | Validation Acc: 0.8098\n",
      "\n",
      "\n",
      "Model Trained Successfully!\n",
      "Training completed in 4.25 minutes\n",
      "\n",
      "Test Accuracy: 0.8233 | Test Loss: 0.4368\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Mask       0.70      0.34      0.46       179\n",
      "        Mask       0.84      0.96      0.89       636\n",
      "\n",
      "    accuracy                           0.82       815\n",
      "   macro avg       0.77      0.65      0.68       815\n",
      "weighted avg       0.81      0.82      0.80       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Use GPU if available\n",
    "BATCH_SIZE = 32  # Batch size for training \n",
    "EPOCHS = 50  # Number of epochs for training\n",
    "LR = 0.001  # Learning rate for optimizer\n",
    "IMAGE_SIZE = (224, 224)  # Image size for model input\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system') # Set sharing strategy for multiprocessing\n",
    "\n",
    "# Custom Dataset Class\n",
    "class MaskDataset(Dataset):\n",
    "    # Initialize the dataset\n",
    "    def __init__(self, npz_file, transform=None):\n",
    "        data = np.load(npz_file) # Load the .npz file\n",
    "        \n",
    "        # Load images and labels\n",
    "        self.images = data['images']\n",
    "        self.labels = data['labels']\n",
    "        \n",
    "        self.transform = transform # Transformations to be applied to the images\n",
    "\n",
    "    # Get the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    # Get a single item from the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform: \n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert image to tensor\n",
    "        image = image.float()\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations for training dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert image to tensor\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define transformations for validation and test datasets\n",
    "validation_and_test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading Processed Data...\")\n",
    "train_dataset = MaskDataset(os.path.join('processed_data', 'train.npz'), transform=train_transform)\n",
    "validation_dataset = MaskDataset(os.path.join('processed_data', 'validation.npz'), transform=validation_and_test_transform)\n",
    "test_dataset = MaskDataset(os.path.join('processed_data', 'test.npz'), transform=validation_and_test_transform)\n",
    "print(\"Data Loaded.\")\n",
    "\n",
    "# Create DataLoader for each dataset\n",
    "print(\"\\nCreating DataLoaders...\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(\"DataLoaders Created.\")\n",
    "\n",
    "# Model Definition\n",
    "class MaskDetector(nn.Module):\n",
    "    # Initialize the model\n",
    "    def __init__(self):\n",
    "        super(MaskDetector, self).__init__() # Call the parent constructor\n",
    "        self.base_model = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        self.base_model.features[0][0] = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False) # Modify the first convolutional layer\n",
    "\n",
    "        # Freeze the base model parameters\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.base_model.last_channel, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x) # Pass through the base model\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1)) # Adaptive average pooling\n",
    "        x = torch.flatten(x, 1) # Flatten the output\n",
    "        return self.classifier(x) # Pass through the classifier\n",
    "\n",
    "# Move model to device\n",
    "print(\"\\nInitializing Model...\")\n",
    "model = MaskDetector().to(DEVICE)\n",
    "print(\"Model Initialized.\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "print(\"\\nDefining Loss Function and Optimizer...\")\n",
    "criterion = nn.BCELoss() # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR) # Adam optimizer\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2) # Learning rate scheduler\n",
    "print(\"Loss Function and Optimizer Defined.\")\n",
    "\n",
    "# Training Function\n",
    "def train_model():\n",
    "    best_validation_loss = float('inf') # Initialize best validation loss\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Starting Training...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train() # Set model to training mode\n",
    "        train_loss = 0.0 # Initialize training loss\n",
    "\n",
    "        # Iterate through training data\n",
    "        for images, labels in train_loader: # Get batch of images and labels\n",
    "            images = images.to(DEVICE, non_blocking=True) # Move images to device\n",
    "            labels = labels.float().to(DEVICE, non_blocking=True) # Move labels to device\n",
    "\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            outputs = model(images) # Forward pass \n",
    "            loss = criterion(outputs.squeeze(), labels) # Compute loss\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update weights\n",
    "\n",
    "            # Update training loss \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        validation_loss, validation_acc = evaluate(model, validation_loader) # Compute validation loss and accuracy\n",
    "        scheduler.step(validation_loss) # Adjust learning rate based on validation loss\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset) # Average training loss\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Validation Loss: {validation_loss:.4f} | Validation Acc: {validation_acc:.4f}')\n",
    "\n",
    "        # Save the model if validation loss improves\n",
    "        if validation_loss < best_validation_loss:\n",
    "            best_validation_loss = validation_loss\n",
    "            torch.save(model.state_dict(), 'face_mask_detection_model.pth')\n",
    "            print('Model saved!')\n",
    "        print(\"\\n\")\n",
    "\n",
    "    print(\"Model Trained Successfully!\")\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    # Iterate through validation/test data\n",
    "    with torch.no_grad(): # Disable gradient calculation\n",
    "        # Iterate over batches\n",
    "        for images, labels in data_loader: \n",
    "            images = images.to(DEVICE) # Move images to device\n",
    "            labels = labels.float().to(DEVICE) # Move labels to device\n",
    "            \n",
    "            outputs = model(images) # Forward pass\n",
    "            loss += criterion(outputs.squeeze(), labels).item() * images.size(0) # Compute loss\n",
    "            preds = (outputs > 0.5).float() # Convert probabilities to binary predictions\n",
    "            correct += (preds.squeeze() == labels).sum().item() # Count correct predictions\n",
    "\n",
    "    # Compute average loss and accuracy\n",
    "    avg_loss = loss / len(data_loader.dataset)\n",
    "    accuracy = correct / len(data_loader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Main script\n",
    "# Define the device\n",
    "print(f'\\nUsing device: {DEVICE}')\n",
    "print(f'GPU Name: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "# Dataset statistics\n",
    "print(f'\\nTraining on {len(train_dataset)} samples')\n",
    "print(f'Validating on {len(validation_dataset)} samples')\n",
    "\n",
    "start_time = time.time() # Start time for training\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "train_model() # Train the model\n",
    "print(f'Training completed in {(time.time() - start_time) / 60:.2f} minutes')\n",
    "\n",
    "# Load best model and test\n",
    "model.load_state_dict(torch.load('face_mask_detection_model.pth', weights_only=True))\n",
    "test_loss, test_acc = evaluate(model, test_loader) # Evaluate on test set\n",
    "print(f'\\nTest Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Generate classification report\n",
    "y_true, y_pred = [], []\n",
    "# Iterate through test data\n",
    "with torch.no_grad(): # Disable gradient calculation\n",
    "    # Iterate over batches \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(DEVICE) # Move images to device\n",
    "        outputs = model(images) # Forward pass\n",
    "        preds = (outputs > 0.5).float() # Convert probabilities to binary predictions\n",
    "        y_true.extend(labels.tolist()) # Append true labels\n",
    "        y_pred.extend(preds.cpu().squeeze().tolist()) # Append predicted labels\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_true, y_pred, target_names=['No Mask', 'Mask']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the model for inference\n",
    "class MaskDetector(torch.nn.Module):\n",
    "    def __init__(self): # Initialize the model\n",
    "        super(MaskDetector, self).__init__() # Call the parent constructor\n",
    "        self.base_model = mobilenet_v2(pretrained=True)\n",
    "        self.base_model.features[0][0] = torch.nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False) # Modify the first convolutional layer\n",
    "        \n",
    "        # Freeze the base model parameters\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(self.base_model.last_channel, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x) # Pass through the base model\n",
    "        x = torch.nn.functional.adaptive_avg_pool2d(x, (1, 1)) # Adaptive average pooling\n",
    "        x = torch.flatten(x, 1) # Flatten the output\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Intialize the model to the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MaskDetector().to(device)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load('face_mask_detection_model.pth', map_location=device, weights_only=True))\n",
    "model.eval() # Set model to evaluation mode\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Define the transformation for inference\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize image\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: No Mask (70.75% confidence)\n"
     ]
    }
   ],
   "source": [
    "# Function to predict the mask status of a face in an image \n",
    "def predict(image_path): \n",
    "    img = cv2.imread(image_path) # Read image using OpenCV\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "    img = cv2.resize(img, (224, 224)) # Resize to target size\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device) # Convert to tensor and add batch dimension\n",
    "    \n",
    "    # Predict the mask status\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor) # Forward pass\n",
    "        probability = output.item() # Get probability\n",
    "\n",
    "        label = \"Mask\" if probability > 0.5 else \"No Mask\" # Determine label based on probability\n",
    "        confidence = max(probability, 1 - probability) # Get confidence score\n",
    "    \n",
    "    print(f\"Prediction: {label} ({confidence:.2%} confidence)\") # Print prediction and confidence\n",
    "\n",
    "predict('test_images/test_face.jpg') # Test the prediction function with the given image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Image Prediction with Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the mask status of a face in an image\n",
    "def predict(image_path):\n",
    "    img = cv2.imread(image_path) # Read image using OpenCV\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "    img_resized = cv2.resize(img_rgb, (224, 224)) # Resize to target size\n",
    "    img_tensor = transform(img_resized).unsqueeze(0).to(device) # Convert to tensor and add batch dimension\n",
    "    \n",
    "    # Predict the mask status\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor) # Forward pass\n",
    "        probability = output.item() # Get probability\n",
    "\n",
    "        label = \"Mask\" if probability > 0.5 else \"No Mask\" # Determine label based on probability\n",
    "        confidence = max(probability, 1 - probability) # Get confidence score\n",
    "\n",
    "    # Show the image with label\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(f\"Prediction: {label} ({confidence:.2%} confidence)\", fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "predict('test_images/test_face.jpg') # Test the prediction function with the given image "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
